## Команда

Алексей Виняр:
- собрал корпус
- почитал литературу
- выделил специфические для корпуса проблемы и придумал пути их решения
- составил списки
- подготовил ручную разметку для замера качества

Екатерина Герасименко:
- решала проблемы общего характера
- написала программу
- провела тестирование


## ТЗ

- На входе - текстовый файл с корпусом.
- На выходе - две таблицы, одна для предложений, другая для токенов, со столбцами:
    ID  Start   End Text

### Золотой стандарт

#### Сплиттер
1) считать всё, что заканчивается на ?, ! и многоточие, отдельным предложением.
2) учитывать переносы посреди предложения и считать предложением даже то, внутри чего есть перенос, а маркеров предложения (открывающих знаков препинания, большой буквы) нет.
3) считать улыбочки концом предложения.
4) не делить по сокращениям, если после них нет большой буквы.
+ несколько тривиальных решений (см.ниже в описании программы)

#### Токены
1) Не сохранять пунктуацию как отдельный токен, но сохранять смайлики, а если они пишутся вместе со словом, оторвать и выделить как отдельный токен.
2) вообще не трогать токены с числами и знаки валюты при числах
3) использовать список клитик и список слов, которые мы не хотим разделять по дефису (см.ниже про списки)
4) не делить то, что вероятнее всего означает долгий звук или заикание.
5) не считать разрядку кучей токенов, а склеить ее в один токен

### Корпус

Анекдоты из нескольких сборников.

### Списки

1) список сокращений - из нашего же корпуса, вытащен регулярным выражением и (большей частью) руками.
2) список отделяемых частей - составлен руками
3) список вещей, которые не хотим отделять (имен собственных и др.) - из частотного словаря Ляшевской-Шарова (http://dict.ruslang.ru/freq.php?)


## Программа

Использует модуль nltk и встроенные модули Питона.

### Сплиттер:

1) сначала поделить по ! и ? и знаку многоточия - всегда + учесть и сохранить закрывающие кавычки.
2) потом по явно закрывающим - скобкам и кавычкам-елочкам, если после них идет или перенос, или открывающие кавычки/скобки, или заглавная буква.
3) потом по непонятным " - если после них идет пробел или перенос, а потом большая буква или открывающая кавычка или скобка, а еще если есть перенос а потом дефис/тире - то есть новая реплика.
4) потом по переносам - если до переноса не стоит двоеточие или запятая, а после переноса стоит большая буква, открывающие знаки препинания или дефис/тире.
5) потом по открывающей скобке - если закрывающую мы отделили сплиттером и если это не смайлик.
6) потом по 2 или более открывающим / закрывающим скобкам - это улыбочки, обычно они заканчивают предложение вместо точки
7) потом по точке - сначала всё, после чего идет пробел или большая буква, потом удаляем знак сплиттера там, где мы поставили его внутри сокращений, после сокращений или одиночной заглавной буквы, и если после сокращений через пробел не стоит заглавная буква. Еще удалить сплиттер, если перед точкой одна заглавная буква, или две заглавных буквы, а после заглавная буква (скорее всего, инициалы).

+ определяются границы предложений: для каждого - индекс его начала, индекс его конца (в смысле, не индекс последнего символа, а +1). Индексы - по сырому тексту со всеми его переносами и десятью точками подряд..........


### Токенизатор:

1) сначала удаляем разрядку - пробел + четыре и более букв через пробел.
1) делим по пробелам, нижнему подчеркиванию и переносу строки.
2) у каждого слова обрезаем знаки препинания, если это не смайлик и не число со знаком валюты.
3) улыбочки отделяем от основного слова в отдельный токен
4) делим по штукам внутри слова: 
    а) комбинации с числами оставляем как есть   
    б) оставляем все неожиданные символы ($#&) внутри слова - это цензура мата.
    в) делим по внутресловным запятой, воскл.знаку, вопросу, скобкам, кавычкам, слешу.
    г) а проблема с точкой уже решилась в сплиттере...
5) дефисы:
    а) комбинации с числами оставляем как есть
    б) если слово начинается или кончается на что-то из списка на отделение и не похож ни на что из списка на неотделение (расстояние Левенштейна больше двух), то тогда разделяем на два токена
    в) если слово похоже на что-то из списка на неотделение, оставляем как один токен
    г) если в разделенном слове длина хотя бы одной из частей не больше двух - оставляем как один токен
    д) если длины всех частей больше двух - делим
 
+ определяются границы токенов, аналогично границам предложений.
ID токена - номер_предложения-номер_токена_в_предложении 


## Тестирование

### Тест (а).
6 анекдотов с разными сложностями.

Тест 1:
- предложение разорвано переносом
- десятичная дробь
- не стоит знак между двумя предложениями.
Первые две проблемы решены, третья представляется неразрешимой (будет больше мусора, чем удачных случаев)

Тест 2:
- прямая речь
- дефисы
Прямая речь отделяется от слов автора, когда в ней стоит восклицательный, вопросительный знак или многоточие (решение в золотом стандарте). В ином случае - не отделяется.
Токен а-а-а не разделяется по дефисам, потому что во всех частях всего один символ.

Тест 3:
- буквенно-числовые и числовые комплексы
- сокращение
Сокращение учтено, буквенно-числовые и числовые комплексы не разделены.

Тест 4:
- цензура мата
- число со знаком валюты
- прямая речь
Прямая речь не отделяется, знак валюты сохранен (но с ним сохранилась и запятая), знаки цензуры сохранены.

Тест 5:
- прямая речь
- дефисы
Прямая речь разделена правильно, по дефисам не разделено, так как в каждой части слова не больше двух символов.

Тест 6:
- смайлик
- ничем не обозначенная прямая речь (как в тесте 1)
Смайлик - отдельный токен и конец предложения. Вторая проблема - слишком сложно...


### Тест (б).
Замер качества
На подвыборке из корпуса.

Предложения:
В целом, 89 совпадений из 140 предложений, размеченных человеком, то есть 63,5%
Однако разметчик всегда отделял слова автора (Чебурашка звонит Гене: \\ -- Гена, нам посылка пришла.), а программа такие случаи не разделяет.  Так что в 23 случаях на одно предложение от программы приходится два предложения аннотатора.
Действительно сложных мест - всего 2:
    а) программа удаляет реплики вида - ...
    б) в одном отрывке отсутствовали знаки препинания между предложениями.
   
Токены:
Всего 551 токен, несколько средней сложности случаев, но в целом отрывок несложный для токенизации.
Одно расхождение - "ну...как". Программа посчитала за один токен, потому что так может быть закрыт мат. Аннотатор разделил на два слова.
Таким образом, точность - 549/551 - 99%.